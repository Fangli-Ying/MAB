# Welcome to your Jupyter Book

This online textbook provides a comprehensive introduction of Multi-Armed Bandits (MAB), covering theoretical foundations, algorithm design, and advanced applications in sequential decision-making under uncertainty. Written by Fangli Ying (ECUST) for Teaching Fellow in a Summer Camp with Prof. Osman YaÄŸan (CMU), it progresses from stochastic bandit fundamentals (UCB, ETC algorithms) to Bayesian methods (Thompson Sampling), structured bandits with hidden parameters, and adversarial settings, featuring rigorous mathematical analysis, regret bounds, and real-world case studies in recommendation systems, wireless communications, and healthcare.

```{tableofcontents}
```
